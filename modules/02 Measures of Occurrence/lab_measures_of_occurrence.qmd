---
title: "Lab: Measures of Occurrence"
format:
  html:
    embed-resources: true
---


# Load packages

Remember, it's considered a best practice to load all the packages that your file will use up at the top of the file. If you have not yet installed a package, you will need to do so by running `install.packages("package name")` in the R console. For example, to install the `freqtables` package, you would run `install.packages("freqtables")`. However, you typically **do not** want to type the code to install the package here in your Rmd file. That is because you only need to install the package once on a given computer. Not every time you run your R code.

```{r message=FALSE}
library(dplyr, warn.conflicts = FALSE)
library(freqtables)
library(ggplot2)
```


# Overview

In today’s lab we will practice performing an interpreting descriptive analysis on categorical and numerical variables using R. We will also practice calculating common measures of prevalence and incidence. Sometimes calculating statistics by hand, and then checking them with statistical software, can help you develop a better intuition for interpreting output.


# Task 1

Please create a data frame in R using the following data from the [United States Census Bureau website](https://data.census.gov/).

* Name the data **census**   
* When creating the **census** data frame, please use the following column names (you don’t need to type the definitions anywhere. They are just written below for your benefit):    
    - **state**: Abbreviated state name.   
    - **region**: Region the state is located in.     
    - **pop**: The total population of the state.   
    - **pop65**: The population of people in the state who are age 65 or older.    
    - **medage**: The median age of the state.   

"AL", "South", 4779736, 657792, 37.9,   
"AK", "West", 710231, 54938, 33.8,   
"AZ", "West", 6392017, 881831, 35.9,   
"AR", "South", 2915918, 419981, 37.4,   
"CA", "West", 37253956, 4246514, 35.2,    
"CO", "West", 5029196, 549625, 36.1,     
"CT", "NE", 3574097, 506559, 40.0,     
"DE", "South", 897934, 129277, 38.8,    
"FL", "South", 18801310, 3259602, 40.7,   
"GA", "South", 9687653, 1032035, 35.3,   
"HI", "West", 1360301, 195138, 38.6,   
"ID", "West", 1567582, 194668, 34.6,   
"IL", "NCntrl", 12830632, 1609213, 36.6,   
"IN", "NCntrl", 6483802, 6483802, 37.0,   
"IA", "NCntrl", 3046355, 452888, 38.1,   
"KS", "NCntrl", 2853118, 376116, 36.0,   
"KY", "South", 4339367, 578227, 38.1,   
"LA", "South", 4533372, 557857, 35.8,   
"ME", "NE", 1328361, 211080, 42.7,   
"MD", "South", 5773552, 707642, 38.0,   
"MA", "NE", 6547629, 902724, 39.1,   
"MI", "NCntrl", 9883640, 1361530, 38.9,   
"MN", "NCntrl", 5303925, 683121, 37.4,   
"MS", "South", 2967297, 380407, 36.0,   
"MO", "NCntrl", 5988927, 838294, 37.9,   
"MT", "West", 989415, 146742, 39.8,   
"NE", "NCntrl", 1826341, 246677, 36.2,   
"NV", "West", 2700551, 324359, 36.3,   
"NH", "NE", 1316470, 178268, 41.1,   
"NJ", "NE", 8791894, 1185993, 39.0,   
"NM", "West", 2059179, 272255, 36.7,   
"NY", "NE", 19378102, 2617943, 38.0,   
"NC", "South", 9535483, 1234079, 37.4,   
"ND", "NCntrl", 672591, 97477, 37.0,   
"OH", "NCntrl", 11536504, 1622015, 38.8,   
"OK", "South", 3751351, 506714, 36.2,   
"OR", "West", 3831074, 533533, 38.4,   
"PA", "NE", 12702379, 1959307, 40.1,   
"RI", "NE", 1052567, 151881, 39.4,   
"SC", "South", 4625364, 631874, 37.9,   
"SD", "NCntrl", 814180, 116581, 36.9,   
"TN", "South", 6346105, 853462, 38.0,   
"TX", "South", 25145561, 2601886, 33.6,   
"UT", "West", 2763885, 249462, 29.2,   
"VT", "NE", 625741, 91078, 41.5,   
"VA", "South", 8001024, 976937, 37.5,   
"WA", "West", 6724540, 827677, 37.3,   
"WV", "South", 1852994, 297404, 41.3,   
"WI", "NCntrl", 5686986, 777314, 38.5,   
"WY", "West", 563626, 70090, 36.8   

```{r}
census <- tibble::tribble(
  ~state, ~region,  ~pop,     ~pop65,  ~medage,
  "AL",   "South",  4779736,  657792,  37.9,
  "AK",   "West",   710231,   54938,   33.8,
  "AZ",   "West",   6392017,  881831,  35.9,
  "AR",   "South",  2915918,  419981,  37.4,
  "CA",   "West",   37253956, 4246514, 35.2, 
  "CO",   "West",   5029196,  549625,  36.1, 
  "CT",   "NE",     3574097,  506559,  40.0, 
  "DE",   "South",  897934,   129277,  38.8,
  "FL",   "South",  18801310, 3259602, 40.7,
  "GA",   "South",  9687653,  1032035, 35.3,
  "HI",   "West",   1360301,  195138,  38.6,
  "ID",   "West",   1567582,  194668,  34.6,
  "IL",   "NCntrl", 12830632, 1609213, 36.6,
  "IN",   "NCntrl", 6483802,  6483802, 37.0,
  "IA",   "NCntrl", 3046355,  452888,  38.1,
  "KS",   "NCntrl", 2853118,  376116,  36.0,
  "KY",   "South",  4339367,  578227,  38.1,
  "LA",   "South",  4533372,  557857,  35.8,
  "ME",   "NE",     1328361,  211080,  42.7,
  "MD",   "South",  5773552,  707642,  38.0,
  "MA",   "NE",     6547629,  902724,  39.1,
  "MI",   "NCntrl", 9883640,  1361530, 38.9,
  "MN",   "NCntrl", 5303925,  683121,  37.4,
  "MS",   "South",  2967297,  380407,  36.0,
  "MO",   "NCntrl", 5988927,  838294,  37.9,
  "MT",   "West",   989415,   146742,  39.8,
  "NE",   "NCntrl", 1826341,  246677,  36.2,
  "NV",   "West",   2700551,  324359,  36.3,
  "NH",   "NE",     1316470,  178268,  41.1,
  "NJ",   "NE",     8791894,  1185993, 39.0,
  "NM",   "West",   2059179,  272255,  36.7,
  "NY",   "NE",     19378102, 2617943, 38.0,
  "NC",   "South",  9535483,  1234079, 37.4,
  "ND",   "NCntrl", 672591,   97477,   37.0,
  "OH",   "NCntrl", 11536504, 1622015, 38.8,
  "OK",   "South",  3751351,  506714,  36.2,
  "OR",   "West",   3831074,  533533,  38.4,
  "PA",   "NE",     12702379, 1959307, 40.1,
  "RI",   "NE",     1052567,  151881,  39.4,
  "SC",   "South",  4625364,  631874,  37.9,
  "SD",   "NCntrl", 814180,   116581,  36.9,
  "TN",   "South",  6346105,  853462,  38.0,
  "TX",   "South",  25145561, 2601886, 33.6,
  "UT",   "West",   2763885,  249462,  29.2,
  "VT",   "NE",     625741,   91078,   41.5,
  "VA",   "South",  8001024,  976937,  37.5,
  "WA",   "West",   6724540,  827677,  37.3,
  "WV",   "South",  1852994,  297404,  41.3,
  "WI",   "NCntrl", 5686986,  777314,  38.5,
  "WY",   "West",   563626,   70090,   36.8
)
```

### Notes for students

1. Notice that I used the `tribble()` function, which is loaded with the `dplyr` package (it's also in the `tibble` package). I did not have to use the `tribble()` function, but doing so saved me some time. I would have had to manually type in the values as columns (vectors) if I used the `data.frame()` function. Using the `tribble()` function allowed me to simply cut and past the data as it was given to me. 


# Task 2

Please create a new factor variable for each of the categorical variables in the **census** data frame (i.e., **state** and **region**). Please use the _f naming convention when you create these new columns.

```{r}
census <- census %>% 
  mutate(
    state_f = factor(state),
    region_f = factor(region)
  )
```


# Task 3

Please view the structure of the data frame you created above using the `str()` or `dplyr::glimpse()` functions.

```{r}
glimpse(census)
```

## Question 1

When you viewed the structure of the **census** data frame above, how many columns were there?

* There are 7 columns in the **census** data frame. They are **state**, **region**, **pop**, **pop65**, **medage**, **state_f**, and **region_f**.


# Task 4

Use R to calculate the frequencies for the region_f variable.

```{r}
# Using base R
table(census$region_f)
```

```{r}
# Using gmodels::CrossTable
gmodels::CrossTable(census$region_f)
```

```{r}
# Using dplyr
census %>% 
  count(region_f)
```

```{r}
# Using freqtables
census %>% 
  freq_table(region_f)
```

## Question 2   

Which region contains the largest number of states?

* The South region has the largest number of states (n = 16). We can see this in our calculated frequencies. 

## Question 3

How many states are in the NCntrl AND NE region?  

* This is sort of a trick question. There are 12 states in the NCntrl region and there are 9 states in the NE region. However, there aren't any states that appear in both the NCntrl _AND_ NE region. There is a reason for creating a tricky question like this. In most programming languages (including R), the words AND and OR have special meaning and are interpreted very literally. It's best if you start adjusting to it now. This concept typically causes some students problems in later learning modules.


# Task 5

Porcellini et al. studied 13 HIV-positive patients who were treated with highly active antiretroviral therapy (HAART) for at least 6 months. The CD4 T cell counts at baseline for the 13 participants are listed below (Daniel, 2005).

230 205 313 207 227 245 173 58 103 181 105 301 169

- Please use this data to create a numerical vector in R. 
- Please name the vector **cd4_counts**.

```{r}
cd4_counts <- c(230, 205, 313, 207, 227, 245, 173, 58, 103, 181, 105, 301, 169)
```


# Task 6

Use R to calculate the mean, median, standard deviation, minimum value, and maximum value of this vector.

```{r}
tibble(
  mean   = mean(cd4_counts),
  median = median(cd4_counts),
  sd     = sd(cd4_counts),
  min    = min(cd4_counts),
  max    = max(cd4_counts)
)
```

### Notes for students

1. Notice that I nested all the individual statistical calculations above inside of the `tibble()` function. You do not have to do this. I just think it makes the output easier to read when it is labeled and presented side-by-side like this. Additionally, adding all of our descriptive statistics to a data frame like this would allow us to save them as a group. This can sometimes be useful when we want to use these statistics again later -- either in our final presentation of results or as inputs to additional calculations. 

## Question 4

What is the mean CD4 T cell count for these 13 participants (rounded to the nearest tenth)?

* 193.6

## Question 5

What is the median CD4 T cell count for these 13 participants?

* 205


# Task 7

Thilothammal et al. designed a study to determine the efficacy of BCG (bacillus Calmette-
Guérin) vaccine in preventing tuberculosis meningitis. Among the data collected on each subject
was a measure of nutritional status (actual weight expressed as a percentage of expected weight
for actual height). The nutritional status values of the 107 cases studied are listed below (Daniel,
2005).

73.3 54.6 82.4 76.5 72.2 73.6 74.0 80.5 71.0 56.8 80.6 100.0 79.6 67.3 50.4 66.0 83.0 72.3 55.7
64.1 66.3 50.9 71.0 76.5 99.6 79.3 76.9 96.0 64.8 74.0 72.6 80.7 109.0 68.6 73.8 74.0 72.7 65.9
73.3 84.4 73.2 70.0 72.8 73.6 70.0 77.4 76.4 66.3 50.5 72.0 97.5 130.0 68.1 86.4 70.0 73.0 59.7
89.6 76.9 74.6 67.7 91.9 55.0 90.9 70.5 88.2 70.5 74.0 55.5 80.0 76.9 78.1 63.4 58.8 92.3 100.0
84.0 71.4 84.6 123.7 93.7 76.9 79.6 45.6 92.5 65.6 61.3 64.5 72.7 77.5 76.9 80.2 76.9 88.7 78.1
60.6 59.0 84.7 78.2 72.4 68.3 67.5 76.9 82.6 85.4 65.7 65.9

- Please use this data to create a numerical vector in R. 
- Please name the vector **nutritional_status**.

```{r}
nutritional_status <- c(73.3, 54.6, 82.4, 76.5, 72.2, 73.6, 74.0, 80.5, 71.0, 56.8, 80.6, 100.0, 79.6, 67.3, 50.4, 66.0, 83.0, 72.3, 55.7, 64.1, 66.3, 50.9, 71.0, 76.5, 99.6, 79.3, 76.9, 96.0, 64.8, 74.0, 72.6, 80.7, 109.0, 68.6, 73.8, 74.0, 72.7, 65.9, 73.3, 84.4, 73.2, 70.0, 72.8, 73.6, 70.0, 77.4, 76.4, 66.3, 50.5, 72.0, 97.5, 130.0, 68.1, 86.4, 70.0, 73.0, 59.7, 89.6, 76.9, 74.6, 67.7, 91.9, 55.0, 90.9, 70.5, 88.2, 70.5, 74.0, 55.5, 80.0, 76.9, 78.1, 63.4, 58.8, 92.3, 100.0, 84.0, 71.4, 84.6, 123.7, 93.7, 76.9, 79.6, 45.6, 92.5, 65.6, 61.3, 64.5, 72.7, 77.5, 76.9, 80.2, 76.9, 88.7, 78.1, 60.6, 59.0, 84.7, 78.2, 72.4, 68.3, 67.5, 76.9, 82.6, 85.4, 65.7, 65.9)
```

### Notes for students

1. Typing all of these commas in manually can be really tedious. Here's a little tip to make it easier. Use RStudio's find a replace tool.    
  - Place your cursor right in front of the first number in the vector (73.3).  
  - Click the icon for RStudio's find and replace tool. It's at the tope of the source pane and looks like a little magnifying glass.   
  - Type a single empty space in the "Find" box using the space bar.   
  - Type a comma followed by a single empty space in the Replace box.    
  - Click the Replace button repeatedly until you've added a comma between all the values in the vector.   
  - Close the find and replace tool.   
  
2. There's actually a way to make the process above even easier!
  - Click before the 73.3 and drag your mouse to highlight the entire section of numbers.   
  - Open the find and replace tool in the same manner as before.    
  - This time, click the little "In selection" box directly below the "Find" box.   
  - As before, type a single empty space in the "Find" box using the space bar, and type a comma followed by a single empty space in the Replace box.   
  - Now, click the "All" button to the right of the replace button. RStudio will then tell you how many replacements were made.    
  - BE CAREFUL!!! If you forget to check the "In selection" box, then every single space in your file will replaced with a comma and space. If you accidently do this, you can quickly undo it by typing Command + z (on Mac) or Control + z (on Windows).
  

# Task 8

Use R to calculate the mean, median, standard deviation, minimum value, and maximum value of this vector.

```{r}
data.frame(
  mean   = mean(nutritional_status),
  median = median(nutritional_status),
  sd     = sd(nutritional_status),
  min    = min(nutritional_status),
  max    = max(nutritional_status)
)
```

### Notes for students

1. I hope you didn't type the code above again. Copy and paste is your friend here!!


## Question 6

What is the standard deviation of these participants’ nutritional status (rounded to the nearest tenth)?

* The result of `sd(nutritional_status)` was 13.64424, which is 13.6 after rounding to the nearest tenth.


# Task 9

The data below was collected from students in a class. It contains eight variables: **id**, **height**, **weight**, **male** (coded as 1 if the student is male and 0 if the student is female), **bach5300** (coded as 1 if the student took the course BACH5300 and 0 if the student did not take BACH5300), **bios5300** (coded as 1 if the student took the course BIOS5300 and 0 if the student did not take BIOS5300), **epid5300** (coded as 1 if the student took the course EPID5300 and 0 if the student did not take EPID5300), and **gpa**.

1 170 185 1 1 1 1 3.6
2 175 162 1 1 1 1 3.7
3 231 180 1 1 1 1 3.8
4 189 190 1 1 0 1 3.8
5 164 175 1 1 0 1 .
6 178 178 1 1 0 0 3.78
7 . 192 1 1 1 0 3.87
8 184 178 1 1 1 0 3.99
9 186 169 1 1 1 0 3.98
10 174 130 1 1 0 0 4
11 165 140 0 1 0 1 2.8
12 155 125 0 1 1 . 3.56
13 158 126 0 1 1 1 .	
14 156 138 0 1 1 1 2.9
15 168 116 0 1 1 1 3.5
16 145 114 0 1 0 1 3.4
17 158 135 0 1 1 0 3.3
18 110 141 0 1 0 0 3.8
19 153 137 0 1 0 0 3.4
20 165 129 0 1 0 0 3.6

- Please use this data to create a data frame in R.
- Please name the vector **nutritional_status**.

```{r}
class <- tribble(
  ~id, ~height, ~weight, ~male, ~bach5300, ~bios5300, ~epid5300, ~gpa,
  1,  170, 185, 1, 1, 1, 1, 3.6,
  2,  175, 162, 1, 1, 1, 1, 3.7,
  3,  231, 180, 1, 1, 1, 1, 3.8,
  4,  189, 190, 1, 1, 0, 1, 3.8,
  5,  164, 175, 1, 1, 0, 1, NA,
  6,  178, 178, 1, 1, 0, 0, 3.78,
  7,  NA,  192, 1, 1, 1, 0, 3.87,
  8,  184, 178, 1, 1, 1, 0, 3.99,
  9,  186, 169, 1, 1, 1, 0, 3.98,
  10, 174, 130, 1, 1, 0, 0, 4,
  11, 165, 140, 0, 1, 0, 1, 2.8,
  12, 155, 125, 0, 1, 1, NA, 3.56,
  13, 158, 126, 0, 1, 1, 1, NA,
  14, 156, 138, 0, 1, 1, 1, 2.9,
  15, 168, 116, 0, 1, 1, 1, 3.5,
  16, 145, 114, 0, 1, 0, 1, 3.4,
  17, 158, 135, 0, 1, 1, 0, 3.3,
  18, 110, 141, 0, 1, 0, 0, 3.8,
  19, 153, 137, 0, 1, 0, 0, 3.4,
  20, 165, 129, 0, 1, 0, 0, 3.6
)
```

### Notes for students

1. I once again used the find and replace tool to add commas to the data. If you missed the explanation for how to do this, it's in the "Notes for students" section between Task 7 and Task 8.    

2. When I copied and pasted the data lines into the R code chunk above, only the first line was properly indented. I could have clicked in front of each id number and hit the tab key to properly indent each line, but there is an easier way! If you just click and drag to select all the lines you want to indent, then hit the tab key, all the lines will be indented at once.

3. A period was used to represent missing values in the raw data you were given. R, of course, uses the special NA value to represent missing data. So, you had to change all the periods to NA in order to create an R data frame. It's fine if you did this manually, but I'm hoping some of you once again used the find and replace tool. Not only does this make things easier for you, but it is also less error prone. We are pretty likely to overlook a period that needs to be changed. R is not. Here's a second little related tip. If you just entered a period in the find box, then all the periods in the gpa column were highlighted and had to be skipped over. If you entered a period followed by a comma (.,) in the find and replace tool, then only the "missing value" periods should have been highlighted (this assumes that you added the commas first). 


# Task 10

Use R to calculate the number of missing values, mean, median, minimum value, and maximum value of all of the numeric vectors in this data frame (i.e., **height**, **weight**, and **gpa**).

```{r}
class %>% 
  summarise(
    n_miss = sum(is.na(height)),
    mean   = mean(height, na.rm = TRUE),
    median = median(height, na.rm = TRUE),
    min    = min(height, na.rm = TRUE),
    max    = max(height, na.rm = TRUE)
  )
```

```{r}
class %>% 
  summarise(
    n_miss = sum(is.na(weight)),
    mean   = mean(weight, na.rm = TRUE),
    median = median(weight, na.rm = TRUE),
    min    = min(weight, na.rm = TRUE),
    max    = max(weight, na.rm = TRUE)
  )
```

```{r}
class %>% 
  summarise(
    n_miss = sum(is.na(gpa)),
    mean   = mean(gpa, na.rm = TRUE),
    median = median(gpa, na.rm = TRUE),
    min    = min(gpa, na.rm = TRUE),
    max    = max(gpa, na.rm = TRUE)
  )
```

### Notes for students

1. Notice that all three of the code chunks above are identical except for the name of the variable we are analyzing. Writing a bunch of repeated code like this is not considered a best practice. In addition to being tedious to type, it is error-prone and difficult to maintain. There are many ways we could reduce the repetition from the code above, but they require slightly more advanced R programming skills than we have developed at this point. However, you may take a look at [Repeated Operations section of R4Epi](https://www.r4epi.com/introduction-to-repeated-operations) if you are interested in learning more.

2. Notice that I did not use `filter(!is.na(height))`, `filter(!is.na(weight))`, or `filter(!is.na(gpa))` to remove rows with missing data in any of the code chunks above. If I had, then we would not have been able to count the number of missing values. Those rows would have been dropped before the data frame was passed to the `summarise()` function. Instead, we set the `na.rm` argument for the `mean()`, `median()`, `min()`, and `max()` functions to `TRUE`. As you've probably guessed, this tells R to remove the missing values from the vector before calculating the mean, median, min, and max respectively. We could have been using these options all along, but it's more efficient to use a single `filter(!is.na(variable))` in your code when that is an option.

3. Notice how we calculated the number of missing values above -- we nested `is.na()` inside of `sum()`. We did this because the `is.na()` function alone returns a logical vector (i.e., TRUE or FALSE). Specifically, it returns TRUE when a value is missing (`NA`) and FALSE when it is not. For example:

```{r}
na_example <- c(1, 3, NA, 7, NA)
is.na(na_example)
```

* As you've already seen, the `sum()` function just adds the numbers passed to it. For example:

```{r}
sum_example <- c(0, 0, 1, 0, 1)
sum(sum_example)
```

* When you pass a logical vector to an R function that performs calculations on numeric vectors, R will treat `TRUE` as the value `1` and `FALSE` as the value `0`. Therefore, when we pass the `na_example` vector we created above to the `sum()` function, R will treat `FALSE + FALSE + TRUE + FALSE + TRUE` (2) exactly the same as `0 + 0 + 1 + 0 + 1` (2). And of course, the value 2 returned from adding up `FALSE + FALSE + TRUE + FALSE + TRUE` is the same as adding the number of `NA` values.

```{r}
na_example <- c(1, 3, NA, 7, NA)
sum(is.na(na_example))
```

* This little trick (i.e., performing calculations on logical vectors) comes in handy a lot.

## Question 7

Which numeric vectors in this data frame (i.e., **height**, **weight**, and **gpa**) have a missing value for at least one observation?

* height and gpa

## Queston 8

How many non-missing values are there for the variable **gpa**?

* The variable **gpa** has 2 missing values. One at id = 5 and one at id = 13. Therefore, there are 18 non-missing values.


# Task 11

Please calculate the prevalence count of disease in the simulated population shown below during the 24 months of follow-up.

```{r}
# Simulate data for 20 hypothetical people
people <- 1:15
months <- -1:24
pop <- tidyr::expand_grid(person = people, month = months)
rows_per_person <- length(months)
```

```{r}
# Create a function that will allow us to more easily simulate data
person_status <- function(pfu, ar, dis, dec, time_check) {
  total_time <- pfu + ar + dis + dec
  if (total_time != time_check) {
    stop("The total time adds up to ", total_time, " it should add up to ", time_check)
  }
  status <- c(rep("Pre-follow-up", pfu), rep("At Risk", ar), rep("Diseased", dis), rep("Deceased", dec))
}

# For testing
# person_status(1, 2, 3, 8, rows_per_person)
```

```{r}
# Create people
status <- c(
  p01 = person_status(0, 0, 26, 0, rows_per_person),
  p02 = person_status(0, 0, 26, 0, rows_per_person),
  p03 = person_status(1, 1, 24, 0, rows_per_person),
  p04 = person_status(1, 4, 21, 0, rows_per_person),
  p05 = person_status(1, 7, 18, 0, rows_per_person),
  p06 = person_status(1, 5, 3, 17, rows_per_person),
  p07 = person_status(1, 25, 0, 0, rows_per_person),
  p08 = person_status(1, 25, 0, 0, rows_per_person),
  p09 = person_status(1, 13, 7, 5, rows_per_person),
  p10 = person_status(1, 25, 0, 0, rows_per_person),
  p11 = person_status(1, 24, 1, 0, rows_per_person),
  p12 = person_status(1, 2, 0, 23, rows_per_person),
  p13 = person_status(1, 15, 0, 10, rows_per_person),
  p14 = person_status(1, 12, 13, 0, rows_per_person),
  p15 = person_status(1, 2, 23, 0, rows_per_person)
)
```

```{r}
# Add status to pop
pop$status <- status

# Create factor versions of person and status
pop <- pop |> 
  mutate(
    person_f = factor(person, labels = c(paste0(0, 1:9), 10:15)),
    status_f = factor(status, levels = c("Pre-follow-up", "At Risk", "Diseased", "Deceased"))
  )

# Make a reverse order version of person and status
# Status: For bar stacking order
# Person: For displaying person 1 at the top of the y-axis after coord_flip
pop <- pop |> 
  mutate(
    status_f_rev = forcats::fct_rev(status_f),
    person_f_rev = forcats::fct_rev(person_f)
  )

# Print pop to the screen
# pop
```

Next, let's create a figure from our simulated data to make it easier to visualize.

```{r}
# This part makes the bars stack in the correct order.
pop_arranged <-  arrange(pop, status_f_rev)

# Create the figure
plot_lab_measures_of_occurrence <- ggplot(pop_arranged, aes(person_f_rev, month, fill = status_f)) +
  geom_col(width = 1, position = position_dodge(0), color = "black") +
  # Add a line marking the start of follow up
  geom_hline(yintercept = 0, color = "blue") +
  # Add vertical lines to mark the start of each month
  geom_hline(yintercept = 1:24, color = "#f9f9f9") +
  # Show all months on the axis
  scale_y_continuous("Month Follow-up", breaks = months) +
  # Change fill colors
  scale_fill_manual("Status", values = c("white", "orange", "red", "black")) +
  # Change x-axis label
  xlab("Person") +
  # Flip the axes
  coord_flip() +
  # Change other theme elements
  theme(
    # Remove gray background
    panel.background = element_blank(),
    # Move legend
    legend.position = "bottom",
    # Change the color and style of the "months" axis 
    axis.line.x = element_line(
      color = "blue", arrow = grid::arrow(length = unit(0.1, "inches"), type = "closed")
    )
  )
```

```{r}
# Save the plot above and reuse the image below.
ggsave(
  "plot_lab_measures_of_occurrence.png", 
  width = 7.29, height = 4.51
)
```

### Notes for students

1. You do not need to understand or even be able to use any of the code above. I'm simply including in case you are interested. If not, please feel free to ignore it.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

```{r}
# Have R calculate the prevalence count for us
pop |> 
  # Keep only the rows for people who ever have a value of "Diseased" for their
  # status.
  filter(status_f == "Diseased") |> 
  # Calculate how many unique people are left in the data.
  summarise(prevalence_count = length(unique(person)))
```

### Notes for students

1. I used the code above to have R calculate the prevalence count for us. We could have also simply counted the number of people who had disease during follow-up by hand.

## Question 9 

What is the prevalence count of disease in the simulated population during the 24 months of follow-up?

* The prevalence count of disease in the simulated population during the 24 months of follow-up is 10.


# Task 12 

Please calculate the prevalence proportion of disease in the simulated population shown below during the 24 months of follow-up.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

```{r}
# Create a vector containing the number of people with disease
n_condition <- 10
# Create a vector containing the number of people in the population of interest
n_population <- 15
# Calculate the prevalence proportion and assign it to an object called 
# prevalence_prop
prevalence_prop <- n_condition / n_population
# Print the value stored in prevalence_prop to the screen
prevalence_prop
```

## Question 10

What is the prevalence proportion of disease in the simulated population during the 24 months of follow-up (rounded to the nearest hundredths place)?

* The prevalence proportion of disease in the simulated population during the 24 months of follow-up (rounded to the nearest hundredths place) is 0.67.


# Task 13

Please calculate the prevalence odds of disease in the simulated population shown below during the 24 months of follow-up.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

## Question 11

```{r}
# Calculate the prevalence odds and assign it to an object called 
# prevalence_odds
prevalence_odds <- prevalence_prop / (1 - prevalence_prop) # Don't forget parentheses
# Print the value stored in prevalence_odds to the screen
prevalence_odds
```

What is the prevalence odds of disease in the simulated population during the 24 months of follow-up?

* The prevalence odds of disease in the simulated population during the 24 months of follow-up is 2.


# Task 14

Please calculate the incidence count of disease in the simulated population shown below during the 24 months of follow-up.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

```{r}
# Have R calculate the incidence count for us
pop |> 
  # Remove person 1 and person 2. They were not at risk at the start of 
  # follow-up
  filter(person != 1 & person != 2) |> 
  # Keep only the rows for people who ever have a value of "Diseased" for their
  # status.
  filter(status_f == "Diseased") |> 
  # Calculate how many unique people are left in the data.
  summarise(incidence_count = length(unique(person)))
```

### Notes for students

1. I used the code above to have R calculate the incidence count for us. We could have also simply counted the number of people who developed new disease during follow-up by hand.

## Question 12

What is the incidence count of disease in the simulated population during the 24 months of follow-up?

* The incidence count of disease in the simulated population during the 24 months of follow-up is 8.


# Task 15

Please calculate the incidence proportion of disease in the simulated population shown below during the 24 months of follow-up.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

```{r}
# Create a vector containing the number of people with incident disease
incidence_count <- 8
# Create a vector containing the number of people in the population of interest
# who were at risk at the start of follow-up
population_at_risk <- 13
# Calculate the incidence proportion and assign it to an object called 
# incidence_prop
incidence_prop <- incidence_count / population_at_risk
# Print the value stored in prevalence_prop to the screen
incidence_prop
```

## Question 13

What is the incidence proportion of disease in the simulated population during the 24 months of follow-up (rounded to the nearest hundredths place)?

* The incidence proportion of disease in the simulated population during the 24 months of follow-up (rounded to the nearest hundredths place) is 0.62.


# Task 16

Please calculate the incidence odds of disease in the simulated population shown below during the 24 months of follow-up.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

```{r}
# Calculate the incidence odds and assign it to an object called 
# incidence_odds
incidence_odds <- incidence_prop / (1 - incidence_prop) # Don't forget parentheses
# Print the value stored in incidence_odds to the screen
incidence_odds
```

## Question 14

What is the incidence proportion of disease in the simulated population during the 24 months of follow-up (rounded to the nearest tenths place)?

* The incidence proportion of disease in the simulated population during the 24 months of follow-up (rounded to the nearest tenths place) is 1.6.


# Task 17

Please calculate the total person-months at risk in the simulated population shown below during the 24 months of follow-up.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

```{r}
# Calculate person-months at risk
person_months_at_risk <- 3 + 6 + 4 + 24 + 24 + 12 + 24 + 23 + 1 + 14 + 11 + 1
# Print person-months at risk to the screen
person_months_at_risk
```

## Question 15

What is the total person-months at risk in the simulated population during the 24 months of follow-up?

* The total person-months at risk in the simulated population during the 24 months of follow-up is 147.


# Task 18

Please calculate the incidence rate of disease in the simulated population shown below during the 24 months of follow-up.

```{r}
# Print the plot to the screen
plot_lab_measures_of_occurrence
```

```{r}
# Create a vector containing the number of people with incident disease
incidence_count <- 8
# Create a vector containing the person months at risk
person_months_at_risk <- 147
# Calculate the incidence rate and assign it to an object called 
# incidence_rate
incidence_rate <- incidence_count / person_months_at_risk
# Print the value stored in incidence_rate to the screen
incidence_rate
```

## Question 16

What is the incidence rate of disease in the simulated population during the 24 months of follow-up (rounded to the nearest hundredths place)?

* The incidence rate of disease in the simulated population during the 24 months of follow-up (rounded to the nearest hundredths place) is 0.05.
